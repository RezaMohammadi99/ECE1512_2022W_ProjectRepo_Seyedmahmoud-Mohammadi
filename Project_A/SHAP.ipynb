{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SHAP.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOmptMK6g/26Bretub87yDb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#MNIST1D\n","#Dependencies\n","from sklearn.linear_model import LinearRegression\n","from math import factorial\n","\n","#Compute n choose k, used for weighting factors\n","def comb(n, k):\n","    return factorial(n) / factorial(k) / factorial(n - k)\n","\n","#My SHAP function for MNIST1D\n","def my_shap(inputs, labels, model, index):\n","  #Identify input being evaluated\n","  input = inputs[index]\n","  label = labels[index]\n","  #Create explanation map array\n","  exmap = np.zeros(input.size)\n","  #Specify Number of features\n","  M = 40\n","  #Create arrays to feed into linear regression\n","  # x is the coalition vector\n","  x = []\n","  # y is the prediction based on the coalition vector\n","  y = []\n","\n","  \n","  # create all coalition vectors to be sampled\n","  for a in range(input.size):\n","    # initialize coalition vector\n","    feat = np.zeros(input.size)\n","    # set one (a-th) feature on\n","    feat[a] = 1\n","    # compile coalition vectors including only the ath feature and excluding only the ath feature\n","    x.append(feat)\n","    x.append(1 - feat)\n","  \n","  # get predictions for all coalition vectors from the model\n","  for e in range(np.shape(x)[0]):\n","    # create temporary input vector\n","    new_input = np.zeros(input.size)\n","    # fill input vector\n","    for f in range(input.size):\n","      # if the feature is included, sample feature from the input being evaluated\n","      # if the feature is not included (else), sample a random feature from the dataset\n","      if x[e][f] == 1:\n","        new_input[f] = input[f]\n","      else:\n","        # set edge case to 0, average for rest\n","        if f == 0 | f == input.size -1:\n","          new_input[f] = 0\n","        else:\n","          new_input[f] = (input[f-1]+input[f+1])/2\n","    # generate prediction for the new input vector\n","    pred = model.predict(np.expand_dims(np.expand_dims(new_input, axis=0), axis=-1))\n","    # compile predictions into array\n","    y.append(pred)\n","\n","  # fix dimensions of array to work with linear regression\n","  y = np.asarray(y)\n","  y = y[:,:,label]\n","  \n","  # create weight vector\n","  pie = np.zeros(np.shape(x)[0])\n","  # calculate weights\n","  for p in range(pie.size):\n","    z_prime = sum(x[p])\n","    pie[p] = (M-1) / (z_prime * (M - z_prime) * comb(M, z_prime))\n","\n","  # find linear regression between predictions and coalition vectors, with weightings\n","  shap = LinearRegression().fit(x,y,pie)\n","\n","  # create explanation map\n","  exmap = shap.coef_.flatten()\n","  exmap -= np.min(exmap)\n","  exmap /= np.max(exmap)\n","  \n","  return exmap"],"metadata":{"id":"v0LvE83hzLO3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#HMT\n","#import libraries to handle linear regression and computation of combinations\n","from sklearn.linear_model import LinearRegression\n","from math import factorial\n","\n","#Compute n choose k, used for weighting factors\n","def comb(n, k):\n","    return factorial(n) / factorial(k) / factorial(n - k)\n","\n","#My SHAP function for HMT\n","def my_shap(inputs, labels, model, index):\n","  #Identify input being evaluated\n","  input = inputs[index]\n","  label = labels[index]\n","  #Specify Number of features, create super cells\n","  M = 49\n","  #Create arrays to feed into linear regression\n","  # x is the coalition vector\n","  x = []\n","  # y is the prediction based on the coalition vector\n","  y = []\n","\n","\n","  # create all coalition vectors to be sampled\n","  for b in range(M):\n","    # initialize coalition vector\n","    feat = np.zeros(M)\n","    # set one (b-th) feature on\n","    feat[b] = 1\n","    # compile coalition vectors including only the bth feature and excluding only the bth feature\n","    x.append(feat)\n","    x.append(1 - feat)\n","\n","\n","  # get predictions for all coalition vectors from the model\n","  for e in range(np.shape(x)[0]):\n","    # create temporary input vector\n","    new_input = np.zeros((224,224,3))\n","    # if the feature is included, sample feature from the input being evaluated\n","    # if the feature is not included (else), zero out the rest of the image\n","    # fill input vector\n","    for f in range(224):\n","      for g in range(224):\n","        val = int(7*np.floor(f/32)+ np.floor(g/32))\n","        if x[e][val] == 1:\n","          new_input[f][g][:] += input[f][g][:]\n","    # generate prediction for the new input vector\n","    pred = model.predict(np.expand_dims(new_input, axis=0))\n","    # compile predictions into array\n","    y.append(pred)\n","\n","  # fix dimensions of array to work with linear regression\n","  y = np.asarray(y)\n","  y = y[:,:,label.argmax()]\n","  \n","  # create weight vector\n","  pie = np.zeros(np.shape(x)[0])\n","\n","  # calculate weights\n","  for p in range(pie.size):\n","    #scaling factor to make factorial computable\n","    z_prime = sum(x[p])\n","    pie[p] = (M-1) / (z_prime * (M - z_prime) * comb(M, z_prime))\n","\n","  # find linear regression between predictions and coalition vectors, with weightings\n","  shap = LinearRegression().fit(x,y,pie)\n","\n","  ## create explanation map, create 224 x 224 representation\n","  exmap = shap.coef_\n","  exmap -= np.min(exmap)\n","  exmap /= np.max(exmap)\n","  exmap = exmap.reshape(7,7)\n","  exmap = np.kron(exmap,np.ones((32,32)))\n","  \n","  return exmap"],"metadata":{"id":"oAttX8d3i_Ht"},"execution_count":null,"outputs":[]}]}